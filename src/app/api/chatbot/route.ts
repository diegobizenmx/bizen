import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

export async function POST(request: NextRequest) {
  try {
    const { message, conversationHistory = [] } = await request.json()

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      )
    }

    // Build conversation context
    const systemMessage = {
      role: "system" as const,
      content: `Eres BIZEN Assistant, un asistente virtual especializado en educaci√≥n financiera para la plataforma BIZEN.

Tu prop√≥sito es ayudar a los usuarios con:

üìö **Educaci√≥n Financiera:**
- Conceptos b√°sicos de finanzas personales
- Presupuestos y ahorro
- Inversiones y cr√©ditos
- Planificaci√≥n financiera
- Identidad digital y seguridad financiera

üéì **Plataforma BIZEN:**
- Navegaci√≥n por m√≥dulos y cursos
- Explicaci√≥n de contenido educativo
- Ayuda con quizzes y evaluaciones
- Progreso y certificaciones
- Problemas t√©cnicos b√°sicos

üí° **Caracter√≠sticas de tu personalidad:**
- Responde siempre en espa√±ol
- S√© amigable, profesional y motivador
- Usa un tono educativo pero accesible
- Proporciona ejemplos pr√°cticos cuando sea posible
- Si no sabes algo, adm√≠telo y sugiere contactar soporte
- Mant√©n las respuestas concisas pero informativas

üîí **L√≠mites:**
- No proporciones consejos financieros espec√≠ficos de inversi√≥n
- No hagas recomendaciones de productos financieros espec√≠ficos
- Si la pregunta es muy t√©cnica o espec√≠fica, sugiere contactar a un asesor financiero profesional

Recuerda: Tu objetivo es educar y empoderar a los usuarios para que tomen mejores decisiones financieras.`
    }

    // Convert conversation history to OpenAI format
    const historyMessages = conversationHistory.map((msg: any) => ({
      role: msg.role,
      content: msg.content
    }))

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        systemMessage,
        ...historyMessages,
        {
          role: "user",
          content: message
        }
      ],
      max_tokens: 500,
      temperature: 0.7,
      presence_penalty: 0.1,
      frequency_penalty: 0.1,
    })

    const response = completion.choices[0].message.content

    if (!response) {
      throw new Error('No se recibi√≥ respuesta del modelo')
    }

    return NextResponse.json({ 
      response: response.trim()
    })

  } catch (error) {
    console.error('OpenAI API error:', error)
    
    // Handle specific OpenAI errors
    if (error instanceof Error) {
      if (error.message.includes('API key')) {
        return NextResponse.json(
          { error: 'Error de configuraci√≥n del servicio' },
          { status: 500 }
        )
      }
      
      if (error.message.includes('rate limit')) {
        return NextResponse.json(
          { error: 'Servicio temporalmente ocupado. Int√©ntalo en unos minutos.' },
          { status: 429 }
        )
      }
    }

    return NextResponse.json(
      { error: 'Error procesando tu pregunta. Por favor, int√©ntalo de nuevo.' },
      { status: 500 }
    )
  }
}

// Handle OPTIONS request for CORS
export async function OPTIONS() {
  return new NextResponse(null, {
    status: 200,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  })
}

